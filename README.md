## ğŸš€ **HRVibe is under active development. Stay tuned!** ğŸ¯

This is the **backend** for HRVibe, built with **Spring Boot** and **MongoDB**.  
It processes **Garmin health data** by fetching it from SQLite, converting it into structured models, and storing it in MongoDB for easy retrieval.

---

## ğŸ“Œ Features

- REST API for **retrieving, storing, and processing Garmin health stats**.
- Uses **MongoDB** for structured health data storage.
- Fetches data from **GarminDB SQLite files** (which are manually updated for now).
- Supports **daily, weekly, monthly, and yearly data summaries**.
- **Future automation planned** for GarminDB fetching & syncing.

---

## ğŸ›  **Tech Stack**

- **Java 23** (Spring Boot)
- **MongoDB** (for storing processed Garmin data)
- **SQLite** (temporary storage before syncing to MongoDB)
- **GitHub Actions** (CI/CD automation)
- **SonarCloud** (code quality analysis)
- **Maven** (dependency management)

---

## ğŸš€ **GitHub Actions Workflows**

This backend uses **GitHub Actions** for CI/CD.

### âœ… `backend-ci.yml` - Java Backend CI

- **Builds** the backend with Maven.
- **Caches dependencies** for faster builds.
- **Ensures the project compiles successfully**.

### âœ… `sonar-backend.yml` - SonarCloud Code Analysis

- **Runs SonarCloud** to check code quality.
- **Caches Sonar dependencies** for faster runs.
- **Ensures the backend meets code standards**.

---

## **ğŸ“Œ How Data is Fetched & Stored**

### **ğŸ”¹ Overview of Data Flow**

1. **GarminDB (SQLite) Fetching:**

   - Manually run `download.py` from the **GarminDB** project.
   - This fetches **new Garmin data** and saves it as `.db` files.

2. **HRVibe Backend Processing:**

   - HRVibe reads **SQLite tables** (`days_summary`, `weeks_summary`, etc.).
   - Converts them into structured **MongoDB documents**.

3. **MongoDB Storage & API Access:**
   - Once in MongoDB, the data is **queried via REST endpoints**.

### **ğŸ”¹ Database & Storage Structure**

ğŸ“‚ **Raw SQLite Data (Before Processing)**

```
GarminDB/GarminData/DBs/
â”œâ”€â”€ garmin.db
â”œâ”€â”€ garmin_summary.db
â”œâ”€â”€ garmin_monitoring.db
```

ğŸ“‚ **Saved JSON Files for Debugging**

```
backend/data/raw_garmin_data/
â”œâ”€â”€ garmin_summary.db/
â”‚     â”œâ”€â”€ days_summary.json
â”‚     â”œâ”€â”€ weeks_summary.json
â”‚     â”œâ”€â”€ months_summary.json
â”‚     â”œâ”€â”€ years_summary.json
â”œâ”€â”€ garmin_monitoring.db/
â”‚     â”œâ”€â”€ heart_rate.json
â”‚     â”œâ”€â”€ intensity.json
```

ğŸ“‚ **Final MongoDB Collections**

| **Model Name**         | **Purpose**                             | **Stored in MongoDB as** |
| ---------------------- | --------------------------------------- | ------------------------ |
| `CurrentDaySummary`    | Latest available dayâ€™s data             | `current_day_summaries`  |
| `RecentDailySummaries` | Last 7 days of daily data (mini-graphs) | `recent_daily_summaries` |
| `WeeklySummary`        | Aggregated weekly data                  | `weekly_summaries`       |
| `MonthlySummary`       | Aggregated monthly data                 | `monthly_summaries`      |
| `YearlySummary`        | Aggregated yearly data                  | `yearly_summaries`       |

---

## **ğŸ“Œ API Endpoints**

### **ğŸ”¹ Fetch GarminDB Table Names**

| Method  | Endpoint                                 | Description                                 |
| ------- | ---------------------------------------- | ------------------------------------------- |
| **GET** | `/api/table-names`                       | Get all available table names from SQLite   |
| **GET** | `/api/fetch-table?tableName={tableName}` | Fetch raw data from a specific SQLite table |
| **GET** | `/api/save-table?tableName={tableName}`  | Save a specific SQLite table as a JSON file |
| **GET** | `/api/save-all-tables`                   | Save all SQLite tables as JSON files        |

---

### **ğŸ”¹ Fetch Processed Data from MongoDB**

Once SQLite data is **processed and stored in MongoDB**, use these endpoints:

| Method  | Endpoint                    | Description                                 |
| ------- | --------------------------- | ------------------------------------------- |
| **GET** | `/api/daily-summary/latest` | Fetch latest available day summary          |
| **GET** | `/api/daily-summary/weekly` | Fetch last 7 days of data (for mini-graphs) |
| **GET** | `/api/weekly-summary`       | Fetch weekly aggregated data                |
| **GET** | `/api/monthly-summary`      | Fetch monthly aggregated data               |
| **GET** | `/api/yearly-summary`       | Fetch yearly aggregated data                |

---

## **âœ… Syncing SQLite Data to MongoDB**

Since automation is **not yet implemented**, we manually trigger syncing.

ğŸ“Œ **Step 1: Run the GarminDB Fetch Script**

```sh
    cd /path/to/GarminDB
    python3 download.py
```

ğŸ“Œ **Step 2: Run HRVibe Backend Sync**

```sh
    curl -X POST http://localhost:8080/api/sync-database
```

ğŸ”¹ **Planned Future Automation**

| Task                       | Current Approach                   | Future Automation                    |
| -------------------------- | ---------------------------------- | ------------------------------------ |
| **GarminDB Data Fetching** | Manual (`python3 download.py`)     | Cron job / Java API trigger          |
| **SQLite â†’ MongoDB Sync**  | Manual (`POST /api/sync-database`) | Scheduled job in Java                |
| **Fetching Only New Data** | Full re-fetch                      | Modify Python to fetch incrementally |

---

## **ğŸ“Œ Notes**

- **Overwriting Behavior:** JSON files **will be replaced** when saving again.
- **MongoDB Data Persistence:** New data is **appended**, not overwritten.
- **Automation:** Planned for **post-MVP phase**.

---

## ğŸ›  **Future Improvements**

- **Automate GarminDB fetching** via cron job or Java API.
- **Schedule SQLite â†’ MongoDB sync** to run nightly.
- **Optimize queries** to fetch **only new data** since last sync.

---

## â­ï¸ **Updating Garmin Data Manually**

- \*\*Make sure to be in the `GarminDB` Project folder.
- \*\*Run the command: `garmindb_cli.py --all --download --import --analyze --latest`
-

